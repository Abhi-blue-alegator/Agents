{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langgraph langchain-openai langchain-community python-docx python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import TypedDict, List, Literal, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import operator\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    conversation_history: Annotated[List[str], operator.add]\n",
    "    test_report: str\n",
    "    generated_questions: List[str]\n",
    "    pending_questions: List[str]\n",
    "    last_follow_up: datetime.datetime\n",
    "    symptoms_collected: bool\n",
    "    report_processed: bool\n",
    "    next_action: Literal[\n",
    "        \"collect_symptoms\", \n",
    "        \"process_report\",\n",
    "        \"clarify_questions\",\n",
    "        \"follow_up\",\n",
    "        \"exit\"\n",
    "    ]\n",
    "    user_input: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLMs\n",
    "llm = ChatOpenAI(temperature=0.2, model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: AgentState):\n",
    "    try:\n",
    "        # Initialize conversation history if empty\n",
    "        if not state.get(\"conversation_history\"):\n",
    "            state[\"conversation_history\"] = [\"Assistant: Hello! I'm your health assistant. Let's start with your symptoms.\"]\n",
    "\n",
    "        # ðŸ”¥ If the user hasn't responded yet, stay in collect_symptoms\n",
    "        if not state.get(\"user_input\", \"\").strip():\n",
    "            print(\"[Supervisor] Waiting for patient response...\")\n",
    "            return {\"next_action\": \"collect_symptoms\"}  # Stay in symptom collection until input is received\n",
    "\n",
    "        # âœ… If symptoms are collected, check what to do next\n",
    "        if state.get(\"symptoms_collected\", False) and state.get(\"report_processed\", False) and not state.get(\"pending_questions\"):\n",
    "            print(\"[Supervisor] Consultation complete. Exiting.\")\n",
    "            return {\"next_action\": \"exit\"}\n",
    "\n",
    "        # ðŸ”¥ Otherwise, analyze and decide  \n",
    "        last_messages = state[\"conversation_history\"][-3:] if len(state[\"conversation_history\"]) >= 3 else state[\"conversation_history\"]\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(content=f\"\"\"You are a medical workflow supervisor. Decide next action:\n",
    "            1. process_report: If test report uploaded but not processed\n",
    "            2. clarify_questions: If pending questions from report\n",
    "            3. follow_up: If time for regular check-in\n",
    "            4. exit: Only when consultation complete\n",
    "            \n",
    "            Current State:\n",
    "            Symptoms Collected: {state.get(\"symptoms_collected\", False)}\n",
    "            Test Report: {'Uploaded' if state.get('test_report') else 'None'}\n",
    "            Pending Questions: {len(state.get('pending_questions', []))}\n",
    "            Conversation Length: {len(state.get('conversation_history', []))}\"\"\"),\n",
    "            HumanMessage(content=\"Recent conversation:\\n\" + \"\\n\".join(last_messages))\n",
    "        ]\n",
    "\n",
    "        decision = llm.invoke(messages).content.lower().strip()\n",
    "        valid_actions = [\"process_report\", \"clarify_questions\", \"follow_up\", \"exit\"]\n",
    "\n",
    "        if decision not in valid_actions:\n",
    "            decision = \"process_report\"  # Default action if LLM is uncertain\n",
    "\n",
    "        print(f\"[Supervisor] Decision: {decision}\")  # Debugging log\n",
    "\n",
    "        return {\"next_action\": decision}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Supervisor error: {str(e)}\")\n",
    "        return {\"next_action\": \"collect_symptoms\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def handle_symptoms(state: AgentState):\n",
    "    try:\n",
    "        messages = [\n",
    "            SystemMessage(content=\"\"\"You are a medical assistant. Your tasks:\n",
    "            1. Ask specific symptom questions\n",
    "            2. Request details about duration, intensity, location\n",
    "            3. Ask one question at a time\n",
    "            4. Maintain professional but friendly tone\"\"\"),\n",
    "            HumanMessage(content=f\"Conversation History:\\n{state.get('conversation_history', [])}\\nPatient Input: {state.get('user_input', '')}\")\n",
    "        ]\n",
    "        \n",
    "        response = llm.invoke(messages).content\n",
    "        return {\n",
    "            \"conversation_history\": [\n",
    "                f\"Patient: {state.get('user_input', '')}\",\n",
    "                f\"Assistant: {response}\"\n",
    "            ],\n",
    "            \"next_action\": \"supervisor\",\n",
    "            \"symptoms_collected\": len(state.get(\"conversation_history\", [])) > 5\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Symptom collection error: {str(e)}\")\n",
    "        return {\"next_action\": \"supervisor\"}\n",
    "\n",
    "def generate_summary(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"\"\"Create a clinical summary for the doctor:\n",
    "        1. Organize symptoms chronologically\n",
    "        2. Highlight key findings from test reports\n",
    "        3. Note patient responses to clarification questions\n",
    "        4. Format with sections: Symptoms, Test Findings, Important Notes\"\"\"),\n",
    "        HumanMessage(content=\"\\n\".join(state[\"conversation_history\"]))\n",
    "    ]\n",
    "    return summary_llm.invoke(messages).content\n",
    "\n",
    "\n",
    "def process_test_report(state: AgentState):\n",
    "    try:\n",
    "        loader = Docx2txtLoader(state[\"test_report\"])\n",
    "        docs = loader.load()\n",
    "        report_content = docs[0].page_content\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=\"\"\"Analyze this test report and generate specific yes/no questions \n",
    "            to verify patient experiences. Format each question as '- [finding]: [question]'\"\"\"),\n",
    "            HumanMessage(content=report_content)\n",
    "        ]\n",
    "        \n",
    "        questions = analysis_llm.invoke(messages).content\n",
    "        return {\n",
    "            \"generated_questions\": [q.strip() for q in questions.split(\"\\n\") if q.strip()],\n",
    "            \"pending_questions\": [q.strip() for q in questions.split(\"\\n\") if q.strip()],\n",
    "            \"test_report\": \"\",  # Reset after processing\n",
    "            \"next_action\": \"supervisor\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"conversation_history\": [f\"Error processing report: {str(e)}\"],\n",
    "            \"next_action\": \"supervisor\"\n",
    "        }\n",
    "\n",
    "def clarify_questions(state: AgentState):\n",
    "    if not state[\"pending_questions\"]:\n",
    "        return {\"next_action\": \"supervisor\"}\n",
    "    \n",
    "    current_question = state[\"pending_questions\"][0]\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Analyze patient's response to the medical question.\"),\n",
    "        HumanMessage(content=f\"\"\"Question: {current_question}\n",
    "        Patient Response: {state['user_input']}\n",
    "        Provide 1-sentence analysis:\"\"\")\n",
    "    ]\n",
    "    \n",
    "    analysis = analysis_llm.invoke(messages).content\n",
    "    return {\n",
    "        \"conversation_history\": [\n",
    "            f\"Asked: {current_question}\",\n",
    "            f\"Patient: {state['user_input']}\",\n",
    "            f\"Analysis: {analysis}\"\n",
    "        ],\n",
    "        \"pending_questions\": state[\"pending_questions\"][1:],\n",
    "        \"next_action\": \"supervisor\"\n",
    "    }\n",
    "\n",
    "def follow_up(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"\"\"Generate follow-up questions based on:\n",
    "        - Conversation history\n",
    "        - Time since last follow-up\n",
    "        - Unresolved medical points\"\"\"),\n",
    "        HumanMessage(content=f\"\"\"Last Follow-up: {state['last_follow_up']}\n",
    "        Conversation History:\\n{state['conversation_history']}\"\"\")\n",
    "    ]\n",
    "    \n",
    "    questions = analysis_llm.invoke(messages).content\n",
    "    return {\n",
    "        \"conversation_history\": [f\"Follow-up: {questions}\"],\n",
    "        \"last_follow_up\": datetime.datetime.now(),\n",
    "        \"next_action\": \"supervisor\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build workflow\n",
    "workflow = StateGraph(AgentState)\n",
    "nodes = {\n",
    "    \"supervisor\": supervisor_node,\n",
    "    \"collect_symptoms\": handle_symptoms,\n",
    "    \"process_report\": process_test_report,\n",
    "    \"clarify_questions\": clarify_questions,\n",
    "    \"follow_up\": follow_up\n",
    "}\n",
    "\n",
    "for name, node in nodes.items():\n",
    "    workflow.add_node(name, node)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda state: state[\"next_action\"],\n",
    "    {action: action for action in nodes.keys() if action != \"supervisor\"} | {\"exit\": END}\n",
    ")\n",
    "\n",
    "for node in [\"collect_symptoms\", \"process_report\", \"clarify_questions\", \"follow_up\"]:\n",
    "    workflow.add_edge(node, \"supervisor\")\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_interface():\n",
    "    state = {\n",
    "        \"conversation_history\": [\"Assistant: Hello! I'm your health assistant. Let's start with your symptoms.\"],\n",
    "        \"test_report\": \"\",\n",
    "        \"generated_questions\": [],\n",
    "        \"pending_questions\": [],\n",
    "        \"last_follow_up\": None,\n",
    "        \"symptoms_collected\": False,\n",
    "        \"report_processed\": False,\n",
    "        \"next_action\": \"collect_symptoms\",\n",
    "        \"user_input\": \"\"\n",
    "    }\n",
    "    \n",
    "    print(state[\"conversation_history\"][0])\n",
    "    while True:\n",
    "        try:\n",
    "            if state[\"next_action\"] == \"process_report\":\n",
    "                report_path = input(\"\\n[System] Please upload test report path: \")\n",
    "                state[\"test_report\"] = report_path\n",
    "                state[\"user_input\"] = \"[REPORT_UPLOADED]\"\n",
    "            else:\n",
    "                user_input = input(\"\\nPatient: \")\n",
    "                state[\"user_input\"] = user_input\n",
    "            \n",
    "            result = agent.invoke(state)\n",
    "            state.update(result)\n",
    "            \n",
    "            if state[\"conversation_history\"]:\n",
    "                print(f\"\\nAssistant: {state['conversation_history'][-1].split('Assistant: ')[-1]}\")\n",
    "            \n",
    "            if state.get(\"next_action\") == \"exit\":\n",
    "                summary = generate_summary(state)\n",
    "                print(f\"\\nConsultation Summary for Doctor:\\n{summary}\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in conversation: {str(e)}\")\n",
    "            state[\"next_action\"] = \"supervisor\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
